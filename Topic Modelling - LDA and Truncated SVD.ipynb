{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ruhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ruhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ruhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = stopwords.words('english')\n",
    "from string import punctuation\n",
    "custom = stop_words+list(punctuation)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('wordnet')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ruhi\\Anaconda3_new\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (5,6,11,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"Consumer_Complaints.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date received</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sub-product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Sub-issue</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>Company public response</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>ZIP code</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Consumer consent provided?</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Date sent to company</th>\n",
       "      <th>Company response to consumer</th>\n",
       "      <th>Timely response?</th>\n",
       "      <th>Consumer disputed?</th>\n",
       "      <th>Complaint ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>562059</th>\n",
       "      <td>04/21/2017</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>False statements or representation</td>\n",
       "      <td>Attempted to collect wrong amount</td>\n",
       "      <td>A charge was made by a company making false cl...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>CITIBANK, N.A.</td>\n",
       "      <td>NH</td>\n",
       "      <td>03061</td>\n",
       "      <td>Older American</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>04/21/2017</td>\n",
       "      <td>Closed with monetary relief</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2446820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562662</th>\n",
       "      <td>04/21/2017</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>Taking/threatening an illegal action</td>\n",
       "      <td>Attempted to/Collected exempt funds</td>\n",
       "      <td>This debt is beyond the Maryland Statute of Li...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>Army and Air Force Exchange Service</td>\n",
       "      <td>MD</td>\n",
       "      <td>211XX</td>\n",
       "      <td>Servicemember</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>04/21/2017</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2447164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563174</th>\n",
       "      <td>04/20/2017</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Other (i.e. phone, health club, etc.)</td>\n",
       "      <td>False statements or representation</td>\n",
       "      <td>Attempted to collect wrong amount</td>\n",
       "      <td>My personal belongings and vehicle were stolen...</td>\n",
       "      <td>Company believes it acted appropriately as aut...</td>\n",
       "      <td>Nevada Credico, Inc.</td>\n",
       "      <td>NV</td>\n",
       "      <td>890XX</td>\n",
       "      <td>Older American</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>04/20/2017</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2445095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563593</th>\n",
       "      <td>04/19/2017</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Other (i.e. phone, health club, etc.)</td>\n",
       "      <td>Communication tactics</td>\n",
       "      <td>Threatened to take legal action</td>\n",
       "      <td>This complaint is necessary to ensure the reco...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>MORGAN STANLEY &amp; CO. LLC</td>\n",
       "      <td>TN</td>\n",
       "      <td>374XX</td>\n",
       "      <td>Servicemember</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>04/19/2017</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2442844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563760</th>\n",
       "      <td>04/19/2017</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Medical</td>\n",
       "      <td>Cont'd attempts collect debt not owed</td>\n",
       "      <td>Debt was paid</td>\n",
       "      <td>I was taken to the hospital while   XXXX   XXX...</td>\n",
       "      <td>Company believes it acted appropriately as aut...</td>\n",
       "      <td>GOLD KEY CREDIT, INC.</td>\n",
       "      <td>IN</td>\n",
       "      <td>479XX</td>\n",
       "      <td>Servicemember</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>04/19/2017</td>\n",
       "      <td>Closed with non-monetary relief</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2441597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date received          Product                            Sub-product  \\\n",
       "562059    04/21/2017  Debt collection                            Credit card   \n",
       "562662    04/21/2017  Debt collection                            Credit card   \n",
       "563174    04/20/2017  Debt collection  Other (i.e. phone, health club, etc.)   \n",
       "563593    04/19/2017  Debt collection  Other (i.e. phone, health club, etc.)   \n",
       "563760    04/19/2017  Debt collection                                Medical   \n",
       "\n",
       "                                        Issue  \\\n",
       "562059     False statements or representation   \n",
       "562662   Taking/threatening an illegal action   \n",
       "563174     False statements or representation   \n",
       "563593                  Communication tactics   \n",
       "563760  Cont'd attempts collect debt not owed   \n",
       "\n",
       "                                  Sub-issue  \\\n",
       "562059    Attempted to collect wrong amount   \n",
       "562662  Attempted to/Collected exempt funds   \n",
       "563174    Attempted to collect wrong amount   \n",
       "563593      Threatened to take legal action   \n",
       "563760                        Debt was paid   \n",
       "\n",
       "                             Consumer complaint narrative  \\\n",
       "562059  A charge was made by a company making false cl...   \n",
       "562662  This debt is beyond the Maryland Statute of Li...   \n",
       "563174  My personal belongings and vehicle were stolen...   \n",
       "563593  This complaint is necessary to ensure the reco...   \n",
       "563760  I was taken to the hospital while   XXXX   XXX...   \n",
       "\n",
       "                                  Company public response  \\\n",
       "562059  Company has responded to the consumer and the ...   \n",
       "562662  Company has responded to the consumer and the ...   \n",
       "563174  Company believes it acted appropriately as aut...   \n",
       "563593  Company has responded to the consumer and the ...   \n",
       "563760  Company believes it acted appropriately as aut...   \n",
       "\n",
       "                                    Company State ZIP code            Tags  \\\n",
       "562059                       CITIBANK, N.A.    NH    03061  Older American   \n",
       "562662  Army and Air Force Exchange Service    MD    211XX   Servicemember   \n",
       "563174                 Nevada Credico, Inc.    NV    890XX  Older American   \n",
       "563593             MORGAN STANLEY & CO. LLC    TN    374XX   Servicemember   \n",
       "563760                GOLD KEY CREDIT, INC.    IN    479XX   Servicemember   \n",
       "\n",
       "       Consumer consent provided? Submitted via Date sent to company  \\\n",
       "562059           Consent provided           Web           04/21/2017   \n",
       "562662           Consent provided           Web           04/21/2017   \n",
       "563174           Consent provided           Web           04/20/2017   \n",
       "563593           Consent provided           Web           04/19/2017   \n",
       "563760           Consent provided           Web           04/19/2017   \n",
       "\n",
       "           Company response to consumer Timely response? Consumer disputed?  \\\n",
       "562059      Closed with monetary relief              Yes                 No   \n",
       "562662          Closed with explanation              Yes                 No   \n",
       "563174          Closed with explanation              Yes                 No   \n",
       "563593          Closed with explanation              Yes                 No   \n",
       "563760  Closed with non-monetary relief              Yes                 No   \n",
       "\n",
       "        Complaint ID  \n",
       "562059       2446820  \n",
       "562662       2447164  \n",
       "563174       2445095  \n",
       "563593       2442844  \n",
       "563760       2441597  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[[\"Consumer complaint narrative\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>562059</th>\n",
       "      <td>A charge was made by a company making false cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562662</th>\n",
       "      <td>This debt is beyond the Maryland Statute of Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563174</th>\n",
       "      <td>My personal belongings and vehicle were stolen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563593</th>\n",
       "      <td>This complaint is necessary to ensure the reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563760</th>\n",
       "      <td>I was taken to the hospital while   XXXX   XXX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563869</th>\n",
       "      <td>XXXX  repossessed my car without notification ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563906</th>\n",
       "      <td>I was contacted about a judgement from   XXXX ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564410</th>\n",
       "      <td>I have never received medical care at this fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564653</th>\n",
       "      <td>I added an account I had with  XXXX   XXXX   X...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564664</th>\n",
       "      <td>I was trying to contact  XXXX  about an approv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Consumer complaint narrative\n",
       "562059  A charge was made by a company making false cl...\n",
       "562662  This debt is beyond the Maryland Statute of Li...\n",
       "563174  My personal belongings and vehicle were stolen...\n",
       "563593  This complaint is necessary to ensure the reco...\n",
       "563760  I was taken to the hospital while   XXXX   XXX...\n",
       "563869  XXXX  repossessed my car without notification ...\n",
       "563906  I was contacted about a judgement from   XXXX ...\n",
       "564410  I have never received medical care at this fac...\n",
       "564653  I added an account I had with  XXXX   XXXX   X...\n",
       "564664  I was trying to contact  XXXX  about an approv..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(s):\n",
    "    s = s.lower()\n",
    "    tokens = nltk.tokenize.word_tokenize(s)\n",
    "    tokens = [t for t in tokens if len(t)>2] #remove words lesser than 2 in length\n",
    "    tokens = [wordnet_lemmatizer.lemmatize(t) for t in tokens] #lemmatize words\n",
    "    tokens = [t for t in tokens if t not in custom] #remove stopwords and punctuation\n",
    "    tokens = [t for t in tokens if not any(c.isdigit() for c in t)] # remove digits\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=df[\"Consumer complaint narrative\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [my_tokenizer(s) for s in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['charge',\n",
       "  'wa',\n",
       "  'made',\n",
       "  'company',\n",
       "  'making',\n",
       "  'false',\n",
       "  'claim',\n",
       "  'product',\n",
       "  'also',\n",
       "  'added',\n",
       "  'additional',\n",
       "  'product',\n",
       "  'purchased',\n",
       "  'bank',\n",
       "  'honor',\n",
       "  'dispute',\n",
       "  'charging',\n",
       "  'absurd',\n",
       "  'late',\n",
       "  'fee',\n",
       "  'balance',\n",
       "  'paid'],\n",
       " ['debt',\n",
       "  'beyond',\n",
       "  'maryland',\n",
       "  'statute',\n",
       "  'limitation',\n",
       "  'illegal',\n",
       "  'debt',\n",
       "  'collector',\n",
       "  'collect',\n",
       "  'expired',\n",
       "  'debt',\n",
       "  'taken',\n",
       "  'illegal',\n",
       "  'action',\n",
       "  'seizing',\n",
       "  'maryland',\n",
       "  'state',\n",
       "  'refund',\n",
       "  'debt',\n",
       "  'already',\n",
       "  'expired',\n",
       "  'beyond',\n",
       "  'statute',\n",
       "  'limitation',\n",
       "  'year',\n",
       "  'state',\n",
       "  'maryland'],\n",
       " ['personal',\n",
       "  'belonging',\n",
       "  'vehicle',\n",
       "  'stolen',\n",
       "  'xxxx',\n",
       "  '=my',\n",
       "  'locker',\n",
       "  'wa',\n",
       "  'broken',\n",
       "  'police',\n",
       "  'said',\n",
       "  'wa',\n",
       "  'probably',\n",
       "  'inside',\n",
       "  'job=they',\n",
       "  'would',\n",
       "  'let',\n",
       "  'see',\n",
       "  'camera',\n",
       "  'see',\n",
       "  'got',\n",
       "  'car=several',\n",
       "  'people',\n",
       "  'ha',\n",
       "  'article',\n",
       "  'stolen',\n",
       "  'different',\n",
       "  'day.s',\n",
       "  'owe',\n",
       "  'happened',\n",
       "  'xxxx',\n",
       "  'xxxx',\n",
       "  'lost',\n",
       "  'car',\n",
       "  'plus',\n",
       "  'another',\n",
       "  'get',\n",
       "  'another',\n",
       "  'one-',\n",
       "  'talked',\n",
       "  'them-filed',\n",
       "  'police',\n",
       "  'report',\n",
       "  'asking',\n",
       "  'dollar',\n",
       "  'way',\n",
       "  'owe',\n",
       "  'think',\n",
       "  'targeting',\n",
       "  'senior',\n",
       "  'citizen',\n",
       "  'afraid',\n",
       "  \"n't\",\n",
       "  'cancel',\n",
       "  'contract'],\n",
       " ['complaint',\n",
       "  'necessary',\n",
       "  'ensure',\n",
       "  'recovery',\n",
       "  'collection',\n",
       "  'firm',\n",
       "  'fee',\n",
       "  'excessive',\n",
       "  'relative',\n",
       "  'small',\n",
       "  'size',\n",
       "  'note',\n",
       "  'determining',\n",
       "  'factor',\n",
       "  'foreclosure',\n",
       "  'sale',\n",
       "  'currently',\n",
       "  'set',\n",
       "  'xxxx',\n",
       "  'xxxx',\n",
       "  'consideration',\n",
       "  'issue',\n",
       "  'requested',\n",
       "  'relative',\n",
       "  'mortgage',\n",
       "  'complaint',\n",
       "  'xxxx',\n",
       "  'well',\n",
       "  'directly',\n",
       "  'related',\n",
       "  'complaint',\n",
       "  'xxxx',\n",
       "  'xxxx',\n",
       "  'issue',\n",
       "  'precipitated',\n",
       "  'collection',\n",
       "  'action'],\n",
       " ['wa',\n",
       "  'taken',\n",
       "  'hospital',\n",
       "  'xxxx',\n",
       "  'xxxx',\n",
       "  'xxxx',\n",
       "  'xxxx',\n",
       "  'xxxx',\n",
       "  'xxxx',\n",
       "  'xxxx',\n",
       "  'xxxx',\n",
       "  'bill',\n",
       "  'essentially',\n",
       "  'workman',\n",
       "  'compensation',\n",
       "  'injury',\n",
       "  'state',\n",
       "  'ha',\n",
       "  'neglected',\n",
       "  'resolve',\n",
       "  'issue',\n",
       "  'timely',\n",
       "  'manner',\n",
       "  'still',\n",
       "  'process',\n",
       "  'take',\n",
       "  'care',\n",
       "  'bill',\n",
       "  'please',\n",
       "  'contact',\n",
       "  'liaison',\n",
       "  'xxxx',\n",
       "  'xxxx',\n",
       "  'xxxx',\n",
       "  'xxxx',\n",
       "  'xxxx',\n",
       "  'xxxx'],\n",
       " ['xxxx',\n",
       "  'repossessed',\n",
       "  'car',\n",
       "  'without',\n",
       "  'notification',\n",
       "  '...',\n",
       "  'mile',\n",
       "  'home',\n",
       "  'cane',\n",
       "  'handicapped',\n",
       "  'spot',\n",
       "  'handicapped',\n",
       "  'plate',\n",
       "  'wa',\n",
       "  'late',\n",
       "  'getting',\n",
       "  'home',\n",
       "  '...',\n",
       "  'almost',\n",
       "  \"n't\",\n",
       "  'get',\n",
       "  'home'],\n",
       " ['wa',\n",
       "  'contacted',\n",
       "  'judgement',\n",
       "  'xxxx',\n",
       "  'whic',\n",
       "  'javitch',\n",
       "  'block',\n",
       "  'got',\n",
       "  'eactivated',\n",
       "  'understand',\n",
       "  'allowed',\n",
       "  'came',\n",
       "  'payment',\n",
       "  'arrangement',\n",
       "  'per',\n",
       "  'month',\n",
       "  'refuse',\n",
       "  'provide',\n",
       "  'statement',\n",
       "  'billing',\n",
       "  'payment',\n",
       "  'due',\n",
       "  'xxxx',\n",
       "  'month',\n",
       "  'paid',\n",
       "  'late',\n",
       "  'month',\n",
       "  'xxxx',\n",
       "  'attempted',\n",
       "  'several',\n",
       "  'day',\n",
       "  'call',\n",
       "  'discus',\n",
       "  'submitting',\n",
       "  'payment',\n",
       "  'response',\n",
       "  'get',\n",
       "  'phone',\n",
       "  'queue',\n",
       "  'xxxx',\n",
       "  'line',\n",
       "  'count',\n",
       "  'xxxx',\n",
       "  'xxxx',\n",
       "  'put',\n",
       "  'voice',\n",
       "  'mail',\n",
       "  'full',\n",
       "  'leave',\n",
       "  'message',\n",
       "  'hou',\n",
       "  'waiting',\n",
       "  'line',\n",
       "  'submt',\n",
       "  'online',\n",
       "  'payment',\n",
       "  'take',\n",
       "  'payment',\n",
       "  'submitted',\n",
       "  'confirmation',\n",
       "  'number',\n",
       "  'sent',\n",
       "  'fax',\n",
       "  'asking',\n",
       "  'contact',\n",
       "  'sent',\n",
       "  'several',\n",
       "  'messges',\n",
       "  'endless',\n",
       "  'loop',\n",
       "  'trying',\n",
       "  'speak',\n",
       "  'someone',\n",
       "  'called',\n",
       "  'spoke',\n",
       "  'witth',\n",
       "  'operator',\n",
       "  'immediately',\n",
       "  'put',\n",
       "  'recording',\n",
       "  'without',\n",
       "  'listening',\n",
       "  'currently',\n",
       "  'loop',\n",
       "  'tell',\n",
       "  'one',\n",
       "  'ailable',\n",
       "  'assist',\n",
       "  'call',\n",
       "  'returned',\n",
       "  'order',\n",
       "  'receied',\n",
       "  'advised',\n",
       "  'leave',\n",
       "  'message',\n",
       "  'put',\n",
       "  'voice',\n",
       "  'mail',\n",
       "  'take',\n",
       "  'message',\n",
       "  'please',\n",
       "  'try',\n",
       "  'xxxx',\n",
       "  \"n't\",\n",
       "  'know'],\n",
       " ['never', 'received', 'medical', 'care', 'facility'],\n",
       " ['added',\n",
       "  'account',\n",
       "  'xxxx',\n",
       "  'xxxx',\n",
       "  'xxxx',\n",
       "  'chapter',\n",
       "  'xxxx',\n",
       "  'bankruptcy',\n",
       "  'still',\n",
       "  'sent',\n",
       "  'account',\n",
       "  'collection',\n",
       "  'agency',\n",
       "  'named',\n",
       "  'monterey',\n",
       "  'financial',\n",
       "  'based',\n",
       "  'california',\n",
       "  'monterey',\n",
       "  'financial',\n",
       "  'contacted',\n",
       "  'several',\n",
       "  'time',\n",
       "  'collect',\n",
       "  'debt',\n",
       "  'even',\n",
       "  'received',\n",
       "  'paperwork',\n",
       "  'stating',\n",
       "  'account',\n",
       "  'wa',\n",
       "  'included',\n",
       "  'bankruptcy',\n",
       "  'attorney',\n",
       "  'sent',\n",
       "  'paperwork',\n",
       "  'still',\n",
       "  'sent',\n",
       "  'account',\n",
       "  'collection',\n",
       "  'affecting',\n",
       "  'credit',\n",
       "  'report',\n",
       "  'since',\n",
       "  'supposed',\n",
       "  'account',\n",
       "  'first',\n",
       "  'place'],\n",
       " ['wa',\n",
       "  'trying',\n",
       "  'contact',\n",
       "  'xxxx',\n",
       "  'approval',\n",
       "  'repayment',\n",
       "  'plan',\n",
       "  'dialed',\n",
       "  'number',\n",
       "  'invoice',\n",
       "  'xxxx',\n",
       "  'wa',\n",
       "  'directed',\n",
       "  'student',\n",
       "  'loan',\n",
       "  'help',\n",
       "  'center',\n",
       "  'aft',\n",
       "  'half',\n",
       "  'hour',\n",
       "  'talking',\n",
       "  'found',\n",
       "  'agreeing',\n",
       "  'consolidation',\n",
       "  'xxxx',\n",
       "  'student',\n",
       "  'loan',\n",
       "  'monthly',\n",
       "  'payment',\n",
       "  'forgiveness',\n",
       "  'loan',\n",
       "  'year',\n",
       "  'based',\n",
       "  'annual',\n",
       "  'income',\n",
       "  'addition',\n",
       "  'xxxx',\n",
       "  'xxxx',\n",
       "  'explained',\n",
       "  'wa',\n",
       "  'fee',\n",
       "  'cover',\n",
       "  'enrollment',\n",
       "  'fee',\n",
       "  'legal',\n",
       "  'process',\n",
       "  'consolidate',\n",
       "  'xxxx',\n",
       "  'loan',\n",
       "  'later',\n",
       "  'night',\n",
       "  'read',\n",
       "  'document',\n",
       "  'sent',\n",
       "  'signature',\n",
       "  'signed',\n",
       "  'electronically',\n",
       "  'authorizing',\n",
       "  'fee',\n",
       "  'deducted',\n",
       "  'account',\n",
       "  'finished',\n",
       "  'shortly',\n",
       "  'read',\n",
       "  'dept',\n",
       "  'education',\n",
       "  'fee',\n",
       "  'incurred',\n",
       "  'student',\n",
       "  'loan',\n",
       "  'help',\n",
       "  'consolidation',\n",
       "  'tried',\n",
       "  'calling',\n",
       "  'xxxx',\n",
       "  'leave',\n",
       "  'message',\n",
       "  'cancel',\n",
       "  'call',\n",
       "  'wa',\n",
       "  'answered',\n",
       "  'general',\n",
       "  'phone',\n",
       "  'line',\n",
       "  'wa',\n",
       "  'unable',\n",
       "  'leave',\n",
       "  'message',\n",
       "  'send',\n",
       "  'email',\n",
       "  'support',\n",
       "  'center',\n",
       "  'request',\n",
       "  'refund',\n",
       "  'morning',\n",
       "  'fund',\n",
       "  'withdrawn',\n",
       "  'soon',\n",
       "  'hit',\n",
       "  'finish',\n",
       "  'please',\n",
       "  'advise',\n",
       "  'scam',\n",
       "  'get',\n",
       "  'money',\n",
       "  'back']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.corpora import dictionary\n",
    "from gensim import corpora\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word=corpora.Dictionary(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(289 unique tokens: ['absurd', 'added', 'additional', 'also', 'balance']...)\n"
     ]
    }
   ],
   "source": [
    "print(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'absurd': 0, 'added': 1, 'additional': 2, 'also': 3, 'balance': 4, 'bank': 5, 'charge': 6, 'charging': 7, 'claim': 8, 'company': 9, 'dispute': 10, 'false': 11, 'fee': 12, 'honor': 13, 'late': 14, 'made': 15, 'making': 16, 'paid': 17, 'product': 18, 'purchased': 19, 'wa': 20, 'action': 21, 'already': 22, 'beyond': 23, 'collect': 24, 'collector': 25, 'debt': 26, 'expired': 27, 'illegal': 28, 'limitation': 29, 'maryland': 30, 'refund': 31, 'seizing': 32, 'state': 33, 'statute': 34, 'taken': 35, 'year': 36, '=my': 37, 'afraid': 38, 'another': 39, 'article': 40, 'asking': 41, 'belonging': 42, 'broken': 43, 'camera': 44, 'cancel': 45, 'car': 46, 'car=several': 47, 'citizen': 48, 'contract': 49, 'day.s': 50, 'different': 51, 'dollar': 52, 'get': 53, 'got': 54, 'ha': 55, 'happened': 56, 'inside': 57, 'job=they': 58, 'let': 59, 'locker': 60, 'lost': 61, \"n't\": 62, 'one-': 63, 'owe': 64, 'people': 65, 'personal': 66, 'plus': 67, 'police': 68, 'probably': 69, 'report': 70, 'said': 71, 'see': 72, 'senior': 73, 'stolen': 74, 'talked': 75, 'targeting': 76, 'them-filed': 77, 'think': 78, 'vehicle': 79, 'way': 80, 'would': 81, 'xxxx': 82, 'collection': 83, 'complaint': 84, 'consideration': 85, 'currently': 86, 'determining': 87, 'directly': 88, 'ensure': 89, 'excessive': 90, 'factor': 91, 'firm': 92, 'foreclosure': 93, 'issue': 94, 'mortgage': 95, 'necessary': 96, 'note': 97, 'precipitated': 98, 'recovery': 99, 'related': 100, 'relative': 101, 'requested': 102, 'sale': 103, 'set': 104, 'size': 105, 'small': 106, 'well': 107, 'bill': 108, 'care': 109, 'compensation': 110, 'contact': 111, 'essentially': 112, 'hospital': 113, 'injury': 114, 'liaison': 115, 'manner': 116, 'neglected': 117, 'please': 118, 'process': 119, 'resolve': 120, 'still': 121, 'take': 122, 'timely': 123, 'workman': 124, '...': 125, 'almost': 126, 'cane': 127, 'getting': 128, 'handicapped': 129, 'home': 130, 'mile': 131, 'notification': 132, 'plate': 133, 'repossessed': 134, 'spot': 135, 'without': 136, 'advised': 137, 'ailable': 138, 'allowed': 139, 'arrangement': 140, 'assist': 141, 'attempted': 142, 'billing': 143, 'block': 144, 'call': 145, 'called': 146, 'came': 147, 'confirmation': 148, 'contacted': 149, 'count': 150, 'day': 151, 'discus': 152, 'due': 153, 'eactivated': 154, 'endless': 155, 'fax': 156, 'full': 157, 'hou': 158, 'immediately': 159, 'javitch': 160, 'judgement': 161, 'know': 162, 'leave': 163, 'line': 164, 'listening': 165, 'loop': 166, 'mail': 167, 'message': 168, 'messges': 169, 'month': 170, 'number': 171, 'one': 172, 'online': 173, 'operator': 174, 'order': 175, 'payment': 176, 'per': 177, 'phone': 178, 'provide': 179, 'put': 180, 'queue': 181, 'receied': 182, 'recording': 183, 'refuse': 184, 'response': 185, 'returned': 186, 'sent': 187, 'several': 188, 'someone': 189, 'speak': 190, 'spoke': 191, 'statement': 192, 'submitted': 193, 'submitting': 194, 'submt': 195, 'tell': 196, 'try': 197, 'trying': 198, 'understand': 199, 'voice': 200, 'waiting': 201, 'whic': 202, 'witth': 203, 'facility': 204, 'medical': 205, 'never': 206, 'received': 207, 'account': 208, 'affecting': 209, 'agency': 210, 'attorney': 211, 'bankruptcy': 212, 'based': 213, 'california': 214, 'chapter': 215, 'credit': 216, 'even': 217, 'financial': 218, 'first': 219, 'included': 220, 'monterey': 221, 'named': 222, 'paperwork': 223, 'place': 224, 'since': 225, 'stating': 226, 'supposed': 227, 'time': 228, 'addition': 229, 'advise': 230, 'aft': 231, 'agreeing': 232, 'annual': 233, 'answered': 234, 'approval': 235, 'authorizing': 236, 'back': 237, 'calling': 238, 'center': 239, 'consolidate': 240, 'consolidation': 241, 'cover': 242, 'deducted': 243, 'dept': 244, 'dialed': 245, 'directed': 246, 'document': 247, 'education': 248, 'electronically': 249, 'email': 250, 'enrollment': 251, 'explained': 252, 'finish': 253, 'finished': 254, 'forgiveness': 255, 'found': 256, 'fund': 257, 'general': 258, 'half': 259, 'help': 260, 'hit': 261, 'hour': 262, 'income': 263, 'incurred': 264, 'invoice': 265, 'later': 266, 'legal': 267, 'loan': 268, 'money': 269, 'monthly': 270, 'morning': 271, 'night': 272, 'plan': 273, 'read': 274, 'repayment': 275, 'request': 276, 'scam': 277, 'send': 278, 'shortly': 279, 'signature': 280, 'signed': 281, 'soon': 282, 'student': 283, 'support': 284, 'talking': 285, 'tried': 286, 'unable': 287, 'withdrawn': 288}\n"
     ]
    }
   ],
   "source": [
    "print(id2word.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycorpus = [id2word.doc2bow(s) for s in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1),\n",
       "  (1, 1),\n",
       "  (2, 1),\n",
       "  (3, 1),\n",
       "  (4, 1),\n",
       "  (5, 1),\n",
       "  (6, 1),\n",
       "  (7, 1),\n",
       "  (8, 1),\n",
       "  (9, 1),\n",
       "  (10, 1),\n",
       "  (11, 1),\n",
       "  (12, 1),\n",
       "  (13, 1),\n",
       "  (14, 1),\n",
       "  (15, 1),\n",
       "  (16, 1),\n",
       "  (17, 1),\n",
       "  (18, 2),\n",
       "  (19, 1),\n",
       "  (20, 1)],\n",
       " [(21, 1),\n",
       "  (22, 1),\n",
       "  (23, 2),\n",
       "  (24, 1),\n",
       "  (25, 1),\n",
       "  (26, 4),\n",
       "  (27, 2),\n",
       "  (28, 2),\n",
       "  (29, 2),\n",
       "  (30, 3),\n",
       "  (31, 1),\n",
       "  (32, 1),\n",
       "  (33, 2),\n",
       "  (34, 2),\n",
       "  (35, 1),\n",
       "  (36, 1)],\n",
       " [(20, 2),\n",
       "  (37, 1),\n",
       "  (38, 1),\n",
       "  (39, 2),\n",
       "  (40, 1),\n",
       "  (41, 1),\n",
       "  (42, 1),\n",
       "  (43, 1),\n",
       "  (44, 1),\n",
       "  (45, 1),\n",
       "  (46, 1),\n",
       "  (47, 1),\n",
       "  (48, 1),\n",
       "  (49, 1),\n",
       "  (50, 1),\n",
       "  (51, 1),\n",
       "  (52, 1),\n",
       "  (53, 1),\n",
       "  (54, 1),\n",
       "  (55, 1),\n",
       "  (56, 1),\n",
       "  (57, 1),\n",
       "  (58, 1),\n",
       "  (59, 1),\n",
       "  (60, 1),\n",
       "  (61, 1),\n",
       "  (62, 1),\n",
       "  (63, 1),\n",
       "  (64, 2),\n",
       "  (65, 1),\n",
       "  (66, 1),\n",
       "  (67, 1),\n",
       "  (68, 2),\n",
       "  (69, 1),\n",
       "  (70, 1),\n",
       "  (71, 1),\n",
       "  (72, 2),\n",
       "  (73, 1),\n",
       "  (74, 2),\n",
       "  (75, 1),\n",
       "  (76, 1),\n",
       "  (77, 1),\n",
       "  (78, 1),\n",
       "  (79, 1),\n",
       "  (80, 1),\n",
       "  (81, 1),\n",
       "  (82, 3)],\n",
       " [(12, 1),\n",
       "  (21, 1),\n",
       "  (82, 5),\n",
       "  (83, 2),\n",
       "  (84, 3),\n",
       "  (85, 1),\n",
       "  (86, 1),\n",
       "  (87, 1),\n",
       "  (88, 1),\n",
       "  (89, 1),\n",
       "  (90, 1),\n",
       "  (91, 1),\n",
       "  (92, 1),\n",
       "  (93, 1),\n",
       "  (94, 2),\n",
       "  (95, 1),\n",
       "  (96, 1),\n",
       "  (97, 1),\n",
       "  (98, 1),\n",
       "  (99, 1),\n",
       "  (100, 1),\n",
       "  (101, 2),\n",
       "  (102, 1),\n",
       "  (103, 1),\n",
       "  (104, 1),\n",
       "  (105, 1),\n",
       "  (106, 1),\n",
       "  (107, 1)],\n",
       " [(20, 1),\n",
       "  (33, 1),\n",
       "  (35, 1),\n",
       "  (55, 1),\n",
       "  (82, 14),\n",
       "  (94, 1),\n",
       "  (108, 2),\n",
       "  (109, 1),\n",
       "  (110, 1),\n",
       "  (111, 1),\n",
       "  (112, 1),\n",
       "  (113, 1),\n",
       "  (114, 1),\n",
       "  (115, 1),\n",
       "  (116, 1),\n",
       "  (117, 1),\n",
       "  (118, 1),\n",
       "  (119, 1),\n",
       "  (120, 1),\n",
       "  (121, 1),\n",
       "  (122, 1),\n",
       "  (123, 1),\n",
       "  (124, 1)],\n",
       " [(14, 1),\n",
       "  (20, 1),\n",
       "  (46, 1),\n",
       "  (53, 1),\n",
       "  (62, 1),\n",
       "  (82, 1),\n",
       "  (125, 2),\n",
       "  (126, 1),\n",
       "  (127, 1),\n",
       "  (128, 1),\n",
       "  (129, 2),\n",
       "  (130, 3),\n",
       "  (131, 1),\n",
       "  (132, 1),\n",
       "  (133, 1),\n",
       "  (134, 1),\n",
       "  (135, 1),\n",
       "  (136, 1)],\n",
       " [(14, 1),\n",
       "  (17, 1),\n",
       "  (20, 1),\n",
       "  (41, 1),\n",
       "  (53, 1),\n",
       "  (54, 1),\n",
       "  (62, 1),\n",
       "  (82, 7),\n",
       "  (86, 1),\n",
       "  (111, 1),\n",
       "  (118, 1),\n",
       "  (122, 2),\n",
       "  (136, 1),\n",
       "  (137, 1),\n",
       "  (138, 1),\n",
       "  (139, 1),\n",
       "  (140, 1),\n",
       "  (141, 1),\n",
       "  (142, 1),\n",
       "  (143, 1),\n",
       "  (144, 1),\n",
       "  (145, 2),\n",
       "  (146, 1),\n",
       "  (147, 1),\n",
       "  (148, 1),\n",
       "  (149, 1),\n",
       "  (150, 1),\n",
       "  (151, 1),\n",
       "  (152, 1),\n",
       "  (153, 1),\n",
       "  (154, 1),\n",
       "  (155, 1),\n",
       "  (156, 1),\n",
       "  (157, 1),\n",
       "  (158, 1),\n",
       "  (159, 1),\n",
       "  (160, 1),\n",
       "  (161, 1),\n",
       "  (162, 1),\n",
       "  (163, 2),\n",
       "  (164, 2),\n",
       "  (165, 1),\n",
       "  (166, 2),\n",
       "  (167, 2),\n",
       "  (168, 3),\n",
       "  (169, 1),\n",
       "  (170, 3),\n",
       "  (171, 1),\n",
       "  (172, 1),\n",
       "  (173, 1),\n",
       "  (174, 1),\n",
       "  (175, 1),\n",
       "  (176, 5),\n",
       "  (177, 1),\n",
       "  (178, 1),\n",
       "  (179, 1),\n",
       "  (180, 3),\n",
       "  (181, 1),\n",
       "  (182, 1),\n",
       "  (183, 1),\n",
       "  (184, 1),\n",
       "  (185, 1),\n",
       "  (186, 1),\n",
       "  (187, 2),\n",
       "  (188, 2),\n",
       "  (189, 1),\n",
       "  (190, 1),\n",
       "  (191, 1),\n",
       "  (192, 1),\n",
       "  (193, 1),\n",
       "  (194, 1),\n",
       "  (195, 1),\n",
       "  (196, 1),\n",
       "  (197, 1),\n",
       "  (198, 1),\n",
       "  (199, 1),\n",
       "  (200, 2),\n",
       "  (201, 1),\n",
       "  (202, 1),\n",
       "  (203, 1)],\n",
       " [(109, 1), (204, 1), (205, 1), (206, 1), (207, 1)],\n",
       " [(1, 1),\n",
       "  (20, 1),\n",
       "  (24, 1),\n",
       "  (26, 1),\n",
       "  (70, 1),\n",
       "  (82, 4),\n",
       "  (83, 2),\n",
       "  (121, 2),\n",
       "  (149, 1),\n",
       "  (187, 3),\n",
       "  (188, 1),\n",
       "  (207, 1),\n",
       "  (208, 5),\n",
       "  (209, 1),\n",
       "  (210, 1),\n",
       "  (211, 1),\n",
       "  (212, 2),\n",
       "  (213, 1),\n",
       "  (214, 1),\n",
       "  (215, 1),\n",
       "  (216, 1),\n",
       "  (217, 1),\n",
       "  (218, 2),\n",
       "  (219, 1),\n",
       "  (220, 1),\n",
       "  (221, 2),\n",
       "  (222, 1),\n",
       "  (223, 2),\n",
       "  (224, 1),\n",
       "  (225, 1),\n",
       "  (226, 1),\n",
       "  (227, 1),\n",
       "  (228, 1)],\n",
       " [(12, 4),\n",
       "  (20, 5),\n",
       "  (31, 1),\n",
       "  (36, 1),\n",
       "  (45, 1),\n",
       "  (53, 1),\n",
       "  (82, 7),\n",
       "  (111, 1),\n",
       "  (118, 1),\n",
       "  (119, 1),\n",
       "  (145, 1),\n",
       "  (163, 2),\n",
       "  (164, 1),\n",
       "  (168, 2),\n",
       "  (171, 1),\n",
       "  (176, 1),\n",
       "  (178, 1),\n",
       "  (187, 1),\n",
       "  (198, 1),\n",
       "  (208, 1),\n",
       "  (213, 1),\n",
       "  (229, 1),\n",
       "  (230, 1),\n",
       "  (231, 1),\n",
       "  (232, 1),\n",
       "  (233, 1),\n",
       "  (234, 1),\n",
       "  (235, 1),\n",
       "  (236, 1),\n",
       "  (237, 1),\n",
       "  (238, 1),\n",
       "  (239, 2),\n",
       "  (240, 1),\n",
       "  (241, 2),\n",
       "  (242, 1),\n",
       "  (243, 1),\n",
       "  (244, 1),\n",
       "  (245, 1),\n",
       "  (246, 1),\n",
       "  (247, 1),\n",
       "  (248, 1),\n",
       "  (249, 1),\n",
       "  (250, 1),\n",
       "  (251, 1),\n",
       "  (252, 1),\n",
       "  (253, 1),\n",
       "  (254, 1),\n",
       "  (255, 1),\n",
       "  (256, 1),\n",
       "  (257, 1),\n",
       "  (258, 1),\n",
       "  (259, 1),\n",
       "  (260, 2),\n",
       "  (261, 1),\n",
       "  (262, 1),\n",
       "  (263, 1),\n",
       "  (264, 1),\n",
       "  (265, 1),\n",
       "  (266, 1),\n",
       "  (267, 1),\n",
       "  (268, 5),\n",
       "  (269, 1),\n",
       "  (270, 1),\n",
       "  (271, 1),\n",
       "  (272, 1),\n",
       "  (273, 1),\n",
       "  (274, 2),\n",
       "  (275, 1),\n",
       "  (276, 1),\n",
       "  (277, 1),\n",
       "  (278, 1),\n",
       "  (279, 1),\n",
       "  (280, 1),\n",
       "  (281, 1),\n",
       "  (282, 1),\n",
       "  (283, 3),\n",
       "  (284, 1),\n",
       "  (285, 1),\n",
       "  (286, 1),\n",
       "  (287, 1),\n",
       "  (288, 1)]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#contains (word id, no.of timws the word has appeared)\n",
    "mycorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 1),\n",
       " (2, 1),\n",
       " (3, 1),\n",
       " (4, 1),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (7, 1),\n",
       " (8, 1),\n",
       " (9, 1),\n",
       " (10, 1),\n",
       " (11, 1),\n",
       " (12, 1),\n",
       " (13, 1),\n",
       " (14, 1),\n",
       " (15, 1),\n",
       " (16, 1),\n",
       " (17, 1),\n",
       " (18, 2),\n",
       " (19, 1),\n",
       " (20, 1)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycorpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=mycorpus,\n",
    "                                           id2word = id2word,\n",
    "                                           num_topics = 4,\n",
    "                                           random_state=42,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.034*\"home\" + 0.024*\"handicapped\" + 0.024*\"...\" + 0.013*\"xxxx\" + '\n",
      "  '0.013*\"wa\" + 0.013*\"get\" + 0.013*\"n\\'t\" + 0.013*\"late\" + 0.013*\"without\" + '\n",
      "  '0.013*\"car\"'),\n",
      " (1,\n",
      "  '0.016*\"received\" + 0.016*\"medical\" + 0.016*\"facility\" + 0.016*\"never\" + '\n",
      "  '0.016*\"care\" + 0.003*\"xxxx\" + 0.003*\"account\" + 0.003*\"wa\" + 0.003*\"loan\" + '\n",
      "  '0.003*\"debt\"'),\n",
      " (2,\n",
      "  '0.036*\"xxxx\" + 0.029*\"wa\" + 0.019*\"fee\" + 0.019*\"loan\" + 0.015*\"debt\" + '\n",
      "  '0.012*\"maryland\" + 0.012*\"student\" + 0.008*\"product\" + 0.008*\"illegal\" + '\n",
      "  '0.008*\"state\"'),\n",
      " (3,\n",
      "  '0.101*\"xxxx\" + 0.017*\"account\" + 0.017*\"sent\" + 0.017*\"payment\" + '\n",
      "  '0.014*\"collection\" + 0.011*\"wa\" + 0.011*\"issue\" + 0.011*\"complaint\" + '\n",
      "  '0.011*\"still\" + 0.011*\"take\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.print_topics())\n",
    "doc_ids = lda_model[mycorpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW_EXAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=[\"The amount of pollution is increasing day by day\",\n",
    "\"The concert was just great\", \"I love to see Gordon Ramsay cook\",\n",
    "\"Google is introducing a new technlogy\", \"AI robots are great example of great technology present today\",\n",
    "\"All of us were singing in the concert\", \"We have launch campaigns to stop pollution and global warming\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The amount of pollution is increasing day by day',\n",
       " 'The concert was just great',\n",
       " 'I love to see Gordon Ramsay cook',\n",
       " 'Google is introducing a new technlogy',\n",
       " 'AI robots are great example of great technology present today',\n",
       " 'All of us were singing in the concert',\n",
       " 'We have launch campaigns to stop pollution and global warming']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(dataset, columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The amount of pollution is increasing day by day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The concert was just great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love to see Gordon Ramsay cook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google is introducing a new technlogy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AI robots are great example of great technolog...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0   The amount of pollution is increasing day by day\n",
       "1                         The concert was just great\n",
       "2                   I love to see Gordon Ramsay cook\n",
       "3              Google is introducing a new technlogy\n",
       "4  AI robots are great example of great technolog..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(s):\n",
    "    s = s.lower()\n",
    "    tokens = nltk.tokenize.word_tokenize(s)\n",
    "    tokens = [t for t in tokens if len(t)>2] #remove words lesser than 2 in length\n",
    "    tokens = [wordnet_lemmatizer.lemmatize(t) for t in tokens] #lemmatize words\n",
    "    tokens = [t for t in tokens if t not in custom] #remove stopwords and punctuation\n",
    "    tokens = [t for t in tokens if not any(c.isdigit() for c in t)] # remove digits\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=df[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [my_tokenizer(s) for s in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['amount', 'pollution', 'increasing', 'day', 'day'],\n",
       " ['concert', 'wa', 'great'],\n",
       " ['love', 'see', 'gordon', 'ramsay', 'cook'],\n",
       " ['google', 'introducing', 'new', 'technlogy'],\n",
       " ['robot', 'great', 'example', 'great', 'technology', 'present', 'today'],\n",
       " ['singing', 'concert'],\n",
       " ['launch', 'campaign', 'stop', 'pollution', 'global', 'warming']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lsa=[\" \".join(x) for x in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amount pollution increasing day day',\n",
       " 'concert wa great',\n",
       " 'love see gordon ramsay cook',\n",
       " 'google introducing new technlogy',\n",
       " 'robot great example great technology present today',\n",
       " 'singing concert',\n",
       " 'launch campaign stop pollution global warming']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_lsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"]=text_lsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer(stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector=tfidf.fit_transform(df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7x25 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 28 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa=TruncatedSVD(n_components=5,n_iter=100,random_state=42,algorithm=\"randomized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=5, n_iter=100,\n",
       "       random_state=42, tol=0.0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.60385084e-16,  5.86198895e-01, -3.65181966e-16,\n",
       "         3.27631825e-16,  1.42870569e-01, -8.88641694e-16,\n",
       "         5.53325018e-17, -3.65181966e-16,  5.51091774e-01,\n",
       "         1.63815912e-16,  5.53325018e-17, -8.88641694e-16,\n",
       "        -3.65181966e-16,  5.53325018e-17, -6.01667646e-16,\n",
       "         1.42870569e-01, -3.65181966e-16,  1.42870569e-01,\n",
       "         3.28034498e-01, -8.88641694e-16,  5.53325018e-17,\n",
       "         1.42870569e-01,  1.42870569e-01,  3.78156161e-01,\n",
       "        -8.88641694e-16],\n",
       "       [ 2.79988276e-01,  6.85024954e-16,  6.70422962e-17,\n",
       "         5.59976552e-01,  2.67407500e-16,  2.79988276e-01,\n",
       "         1.72293651e-17,  6.70486490e-17,  7.58866298e-16,\n",
       "         2.79988276e-01,  1.72293651e-17,  2.79988276e-01,\n",
       "         6.70486490e-17,  1.72293651e-17,  4.64828628e-01,\n",
       "         2.67410194e-16,  6.70486490e-17,  2.67410194e-16,\n",
       "         4.30854311e-16,  2.79988276e-01,  1.72293651e-17,\n",
       "         2.67410194e-16,  2.67410194e-16,  3.83835360e-16,\n",
       "         2.79988276e-01],\n",
       "       [-1.44114767e-16, -1.57271044e-01,  4.22431331e-01,\n",
       "         1.95005642e-17,  9.47317909e-02, -8.72835381e-17,\n",
       "        -1.97466269e-01,  4.22431331e-01,  1.57271044e-01,\n",
       "         1.34979383e-17, -1.97466269e-01, -8.72835381e-17,\n",
       "         4.22431331e-01, -1.97466269e-01, -6.32488036e-17,\n",
       "         9.47317909e-02,  4.22431331e-01,  9.47317909e-02,\n",
       "        -1.89463582e-01, -8.72835381e-17, -1.97466269e-01,\n",
       "         9.47317909e-02,  9.47317909e-02,  1.73307790e-16,\n",
       "        -8.72850511e-17],\n",
       "       [ 1.51546767e-16, -4.03813264e-01, -1.86396356e-01,\n",
       "         5.72253456e-18,  2.43235835e-01, -3.68590023e-18,\n",
       "         2.46081534e-02, -1.86396356e-01,  4.03813264e-01,\n",
       "        -9.95867102e-18,  2.46081534e-02, -3.68590023e-18,\n",
       "        -1.86396356e-01,  2.46081534e-02, -1.79413999e-18,\n",
       "         2.43235835e-01, -1.86396356e-01,  2.43235835e-01,\n",
       "        -4.86471671e-01, -3.68590023e-18,  2.46081534e-02,\n",
       "         2.43235835e-01,  2.43235835e-01, -3.47318878e-16,\n",
       "        -3.68586387e-18],\n",
       "       [-8.86359527e-17, -4.60406306e-02,  1.91854552e-01,\n",
       "         1.52030189e-17,  2.77324502e-02, -5.24781967e-17,\n",
       "         4.58695445e-01,  1.91854552e-01,  4.60406306e-02,\n",
       "         2.47980529e-18,  4.58695445e-01, -5.24781967e-17,\n",
       "         1.91854552e-01,  4.58695445e-01, -3.96155051e-17,\n",
       "         2.77324502e-02,  1.91854552e-01,  2.77324502e-02,\n",
       "        -5.54649004e-02, -5.24781967e-17,  4.58695445e-01,\n",
       "         2.77324502e-02,  2.77324502e-02, -1.55148187e-16,\n",
       "        -5.24787733e-17]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms=tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lsa.components_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 0 :\n",
      "('concert', 0.5861988946926838)\n",
      "('great', 0.5510917740996545)\n",
      "('wa', 0.37815616140658215)\n",
      "('singing', 0.3280344982744638)\n",
      "('example', 0.14287056933660638)\n",
      "\n",
      "Topic 1 :\n",
      "('day', 0.55997655174895)\n",
      "('pollution', 0.4648286283442407)\n",
      "('campaign', 0.27998827587447517)\n",
      "('global', 0.2799882758744751)\n",
      "('launch', 0.2799882758744751)\n",
      "\n",
      "Topic 2 :\n",
      "('gordon', 0.42243133099973545)\n",
      "('love', 0.42243133099973545)\n",
      "('ramsay', 0.42243133099973545)\n",
      "('cook', 0.4224313309997354)\n",
      "('great', 0.1572710438839122)\n",
      "\n",
      "Topic 3 :\n",
      "('great', 0.40381326442337273)\n",
      "('example', 0.2432358352881226)\n",
      "('present', 0.24323583528812256)\n",
      "('robot', 0.24323583528812256)\n",
      "('technology', 0.24323583528812256)\n",
      "\n",
      "Topic 4 :\n",
      "('google', 0.45869544502220616)\n",
      "('introducing', 0.45869544502220616)\n",
      "('new', 0.45869544502220616)\n",
      "('technlogy', 0.45869544502220616)\n",
      "('gordon', 0.19185455192022857)\n"
     ]
    }
   ],
   "source": [
    "prob = list(terms)\n",
    "for i,y in enumerate(lsa.components_):\n",
    "    componentwords = zip(prob,y)\n",
    "    sortedComponentwords = sorted(componentwords,key=lambda x:x[1],reverse=True)\n",
    "    sortedComponentwords = sortedComponentwords[:5]\n",
    "    print(\"\\nTopic\",i,\":\")\n",
    "    for x in sortedComponentwords:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word=corpora.Dictionary(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(27 unique tokens: ['amount', 'day', 'increasing', 'pollution', 'concert']...)\n"
     ]
    }
   ],
   "source": [
    "print(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycorpus = [id2word.doc2bow(s) for s in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 2), (2, 1), (3, 1)],\n",
       " [(4, 1), (5, 1), (6, 1)],\n",
       " [(7, 1), (8, 1), (9, 1), (10, 1), (11, 1)],\n",
       " [(12, 1), (13, 1), (14, 1), (15, 1)],\n",
       " [(5, 2), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1)],\n",
       " [(4, 1), (21, 1)],\n",
       " [(3, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1)]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=mycorpus,\n",
    "                                           id2word = id2word,\n",
    "                                           num_topics = 4,\n",
    "                                           random_state=42,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto', \n",
    "                                           per_word_topics =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.127*\"concert\" + 0.070*\"pollution\" + 0.070*\"launch\" + 0.070*\"global\" + '\n",
      "  '0.070*\"stop\" + 0.070*\"warming\" + 0.070*\"campaign\" + 0.070*\"wa\" + '\n",
      "  '0.070*\"great\" + 0.070*\"singing\"'),\n",
      " (1,\n",
      "  '0.116*\"new\" + 0.116*\"introducing\" + 0.116*\"google\" + 0.116*\"technlogy\" + '\n",
      "  '0.023*\"singing\" + 0.023*\"concert\" + 0.023*\"great\" + 0.023*\"pollution\" + '\n",
      "  '0.023*\"wa\" + 0.023*\"day\"'),\n",
      " (2,\n",
      "  '0.120*\"great\" + 0.120*\"day\" + 0.067*\"today\" + 0.067*\"technology\" + '\n",
      "  '0.067*\"present\" + 0.067*\"robot\" + 0.067*\"example\" + 0.067*\"amount\" + '\n",
      "  '0.067*\"increasing\" + 0.067*\"pollution\"'),\n",
      " (3,\n",
      "  '0.106*\"love\" + 0.106*\"ramsay\" + 0.106*\"gordon\" + 0.106*\"cook\" + 0.106*\"see\" '\n",
      "  '+ 0.021*\"technlogy\" + 0.021*\"google\" + 0.021*\"introducing\" + 0.021*\"new\" + '\n",
      "  '0.021*\"singing\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.print_topics())\n",
    "doc_ids = lda_model[mycorpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -3.9817473543807864\n"
     ]
    }
   ],
   "source": [
    "print('\\nPerplexity: ', lda_model.log_perplexity(mycorpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.5685180008191147\n"
     ]
    }
   ],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=text, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_path = 'C:/User/Ruhi/Downloads/mallet-2.0.8/mallet-2.0.8/bin/mallet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'C:/User/Ruhi/Downloads/mallet-2.0.8/mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input C:\\Users\\Ruhi\\AppData\\Local\\Temp\\1a97ba_corpus.txt --output C:\\Users\\Ruhi\\AppData\\Local\\Temp\\1a97ba_corpus.mallet' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-fafd5a4850c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mldamallet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLdaMallet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmallet_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmycorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3_new\\lib\\site-packages\\gensim\\models\\wrappers\\ldamallet.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, mallet_path, corpus, num_topics, alpha, id2word, workers, prefix, optimize_interval, iterations, topic_threshold, random_seed)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_seed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfinferencer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3_new\\lib\\site-packages\\gensim\\models\\wrappers\\ldamallet.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, corpus)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m         \"\"\"\n\u001b[1;32m--> 272\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m         \u001b[0mcmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmallet_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' train-topics --input %s --num-topics %s  --alpha %s --optimize-interval %s '\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m             \u001b[1;34m'--num-threads %s --output-state %s --output-doc-topics %s --output-topic-keys %s '\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3_new\\lib\\site-packages\\gensim\\models\\wrappers\\ldamallet.py\u001b[0m in \u001b[0;36mconvert_input\u001b[1;34m(self, corpus, infer, serialize_corpus)\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mcmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcmd\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfcorpustxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfcorpusmallet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"converting temporary corpus to MALLET format with %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m         \u001b[0mcheck_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3_new\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36mcheck_output\u001b[1;34m(stdout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m   1916\u001b[0m             \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1917\u001b[0m             \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1919\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command 'C:/User/Ruhi/Downloads/mallet-2.0.8/mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input C:\\Users\\Ruhi\\AppData\\Local\\Temp\\1a97ba_corpus.txt --output C:\\Users\\Ruhi\\AppData\\Local\\Temp\\1a97ba_corpus.mallet' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=mycorpus, num_topics=20, id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
